{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32027f26-e1da-4a01-a9a7-072f961f0788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "import csv, pydot, graphviz, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(city, district):\n",
    "    data=pd.read_csv(f'../dataset/{city}_model_features.csv')\n",
    "    data = data.loc[data['鄉鎮市區'] == district]\n",
    "    f_count = data.shape[1]\n",
    "    data.insert(f_count, 'y', data['單價元平方公尺'])\n",
    "    data.drop(['單價元平方公尺'],axis=1,inplace=True)\n",
    "    data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "    data.drop(['Unnamed: 0.1'],axis=1,inplace=True)\n",
    "    data.drop(['鄉鎮市區'],axis=1,inplace=True)\n",
    "    data.drop(['建物型態'],axis=1,inplace=True)\n",
    "    data.drop(['車位類別'],axis=1,inplace=True)\n",
    "    data.drop(['geometry'],axis=1,inplace=True)\n",
    "    \n",
    "    path = f'{city}'\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    path = f'{city}/{district}'\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    std = data.std()\n",
    "    std_df = pd.DataFrame(std)\n",
    "    std_df.to_csv(f'{city}/{district}/std.csv')\n",
    "    data = data.loc[:, data.std() > 0]\n",
    "    test_data111 = data.loc[data['交易年份'] == 111]\n",
    "    data =  data.loc[data['交易年份'] < 111]\n",
    "    data = data.dropna()\n",
    "    \n",
    "    data = data.sample(frac=1.0)\n",
    "    data = data.reset_index()\n",
    "    train_data = data.sample(frac=0.8)\n",
    "    \n",
    "    feature_count = train_data.shape[1]\n",
    "    \n",
    "    data2 = data[~data.index.isin(train_data.index)]\n",
    "    \n",
    "    val_data = data2.sample(frac=0.5)\n",
    "    test_data = data2[~data2.index.isin(val_data.index)]\n",
    "    \n",
    "    train_data.drop(['index'],axis=1,inplace=True)\n",
    "    val_data.drop(['index'],axis=1,inplace=True)\n",
    "    test_data.drop(['index'],axis=1,inplace=True)\n",
    "    train_validation_data = pd.concat([train_data, val_data])\n",
    "    mean = train_validation_data.mean()\n",
    "    std = train_validation_data.std()\n",
    "    train_data = (train_data-mean)/std\n",
    "    val_data = (val_data -mean)/std\n",
    "    \n",
    "    X_data = np.array(train_data.drop('y', axis='columns'))\n",
    "    y_data = np.array(train_data['y'])\n",
    "    X_val = np.array(val_data.drop('y', axis='columns'))\n",
    "    y_val = np.array(val_data['y'])\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(keras.layers.Dense(feature_count-1, activation='relu', input_shape=(feature_count-2,))) \n",
    "    model.add(keras.layers.Dense(int(train_data.shape[1]*2/3), activation='relu'))\n",
    "    model.add(keras.layers.Dense(int(train_data.shape[1]*1/3), activation='relu'))\n",
    "    model.add(keras.layers.Dense(1)) \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(keras.optimizers.Adam(0.0001),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    model_mckp=keras.callbacks.ModelCheckpoint(f'{city}/{district}/model-1.h5',monitor='val_mean_absolute_error',save_best_only=True,mode='min')\n",
    "    \n",
    "    model_cbk=keras.callbacks.TensorBoard()\n",
    "    history = model.fit(X_data, y_data,batch_size=10, epochs=100, validation_data=(X_val, y_val),  callbacks=[model_cbk, model_mckp])\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.title('MSE')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{city}/{district}/MSE.png')\n",
    "    plt.cla()\n",
    "    \n",
    "    plt.plot(history.history['mean_absolute_error'], label='train')\n",
    "    plt.plot(history.history['val_mean_absolute_error'], label='validation')\n",
    "    plt.title('MAE')\n",
    "    plt.ylabel('metrics')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{city}/{district}/MAE.png')\n",
    "    \n",
    "    # test\n",
    "    model = keras.models.load_model(f'{city}/{district}/model-1.h5')\n",
    "    y_test = np.array(test_data['y'])\n",
    "    test_data_output = test_data\n",
    "    test_data = (test_data - mean) / std\n",
    "    x_test = np.array(test_data.drop('y', axis='columns'))\n",
    "    y_t = np.array(test_data['y'])\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_p = y_pred\n",
    "    y_pred = np.reshape(y_pred * std['y'] + mean['y'], y_test.shape)\n",
    "    percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "    print(\"Model Percentage Error: {:.2f}%\".format(percentage_error))\n",
    "    print(f\"mean_absolute_error: {mean_absolute_error(y_t, y_p)}\")\n",
    "    print(f\"explained_variance_score: {explained_variance_score(y_t, y_p)}\")\n",
    "    # mean_squared_error\n",
    "    print(f\"mean_squared_error: {mean_squared_error(y_t, y_p)}\")\n",
    "    print(f\"r2_score: {r2_score(y_t, y_p)}\")\n",
    "    f = open(f'{city}/{district}/Accuracy_Index.txt', 'w')\n",
    "    f.write(\"Model Percentage Error: {:.2f}% \\n\".format(percentage_error))\n",
    "    f.write(f\"mean_absolute_error: {mean_absolute_error(y_t, y_p)} \\n\")\n",
    "    f.write(f\"explained_variance_score: {explained_variance_score(y_t, y_p)} \\n\")\n",
    "    f.write(f\"mean_squared_error: {mean_squared_error(y_t, y_p)} \\n\")\n",
    "    f.write(f\"r2_score: {r2_score(y_t, y_p)} \\n\")\n",
    "    f.close()\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    test_data_output.reset_index(drop=True, inplace=True)\n",
    "    result = pd.concat([test_data_output, y_pred],axis=1,ignore_index=True)\n",
    "    result.to_csv(f'{city}/{district}/result.csv')\n",
    "    \n",
    "    # test111\n",
    "    model = keras.models.load_model(f'{city}/{district}/model-1.h5')\n",
    "    y_test = np.array(test_data111['y'])\n",
    "    test_data_output = test_data111\n",
    "    test_data111 = (test_data111 - mean) / std\n",
    "    x_test = np.array(test_data111.drop('y', axis='columns'))\n",
    "    y_t = np.array(test_data111['y'])\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_p = y_pred\n",
    "    y_pred = np.reshape(y_pred * std['y'] + mean['y'], y_test.shape)\n",
    "    percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "    print(\"Model Percentage Error: {:.2f}%\".format(percentage_error))\n",
    "    print(f\"mean_absolute_error: {mean_absolute_error(y_t, y_p)}\")\n",
    "    print(f\"explained_variance_score: {explained_variance_score(y_t, y_p)}\")\n",
    "    # mean_squared_error\n",
    "    print(f\"mean_squared_error: {mean_squared_error(y_t, y_p)}\")\n",
    "    print(f\"r2_score: {r2_score(y_t, y_p)}\")\n",
    "    f = open(f'{city}/{district}/111_Accuracy_Index.txt', 'w')\n",
    "    f.write(\"Model Percentage Error: {:.2f}% \\n\".format(percentage_error))\n",
    "    f.write(f\"mean_absolute_error: {mean_absolute_error(y_t, y_p)} \\n\")\n",
    "    f.write(f\"explained_variance_score: {explained_variance_score(y_t, y_p)} \\n\")\n",
    "    f.write(f\"mean_squared_error: {mean_squared_error(y_t, y_p)} \\n\")\n",
    "    f.write(f\"r2_score: {r2_score(y_t, y_p)} \\n\")\n",
    "    f.close()\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "  \n",
    "    test_data_output.reset_index(drop=True, inplace=True)\n",
    "    result = pd.concat([test_data_output, y_pred],axis=1)\n",
    "    result.to_csv(f'{city}/{district}/111_result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32604db3-d271-4860-ba6a-7db6b2e870ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 83)                6889      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 55)                4620      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 27)                1512      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 28        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,049\n",
      "Trainable params: 13,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7243/1216376041.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.drop(['index'],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "491/491 [==============================] - 2s 3ms/step - loss: 0.8733 - mean_absolute_error: 0.6671 - val_loss: 0.5300 - val_mean_absolute_error: 0.5108\n",
      "Epoch 2/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.5112 - mean_absolute_error: 0.4779 - val_loss: 0.3860 - val_mean_absolute_error: 0.4404\n",
      "Epoch 3/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.4195 - mean_absolute_error: 0.4279 - val_loss: 0.3201 - val_mean_absolute_error: 0.4029\n",
      "Epoch 4/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.3689 - mean_absolute_error: 0.4013 - val_loss: 0.2926 - val_mean_absolute_error: 0.3922\n",
      "Epoch 5/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.3310 - mean_absolute_error: 0.3816 - val_loss: 0.2708 - val_mean_absolute_error: 0.3753\n",
      "Epoch 6/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.3025 - mean_absolute_error: 0.3689 - val_loss: 0.2558 - val_mean_absolute_error: 0.3653\n",
      "Epoch 7/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2780 - mean_absolute_error: 0.3551 - val_loss: 0.2507 - val_mean_absolute_error: 0.3601\n",
      "Epoch 8/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2588 - mean_absolute_error: 0.3453 - val_loss: 0.2470 - val_mean_absolute_error: 0.3569\n",
      "Epoch 9/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2433 - mean_absolute_error: 0.3363 - val_loss: 0.2444 - val_mean_absolute_error: 0.3578\n",
      "Epoch 10/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2312 - mean_absolute_error: 0.3281 - val_loss: 0.2480 - val_mean_absolute_error: 0.3699\n",
      "Epoch 11/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2194 - mean_absolute_error: 0.3199 - val_loss: 0.2383 - val_mean_absolute_error: 0.3484\n",
      "Epoch 12/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2118 - mean_absolute_error: 0.3152 - val_loss: 0.2283 - val_mean_absolute_error: 0.3415\n",
      "Epoch 13/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2037 - mean_absolute_error: 0.3090 - val_loss: 0.2291 - val_mean_absolute_error: 0.3391\n",
      "Epoch 14/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1960 - mean_absolute_error: 0.3028 - val_loss: 0.2283 - val_mean_absolute_error: 0.3423\n",
      "Epoch 15/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1921 - mean_absolute_error: 0.3006 - val_loss: 0.2277 - val_mean_absolute_error: 0.3353\n",
      "Epoch 16/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1849 - mean_absolute_error: 0.2954 - val_loss: 0.2234 - val_mean_absolute_error: 0.3368\n",
      "Epoch 17/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1780 - mean_absolute_error: 0.2886 - val_loss: 0.2277 - val_mean_absolute_error: 0.3366\n",
      "Epoch 18/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1738 - mean_absolute_error: 0.2872 - val_loss: 0.2253 - val_mean_absolute_error: 0.3339\n",
      "Epoch 19/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1690 - mean_absolute_error: 0.2827 - val_loss: 0.2243 - val_mean_absolute_error: 0.3302\n",
      "Epoch 20/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1649 - mean_absolute_error: 0.2809 - val_loss: 0.2269 - val_mean_absolute_error: 0.3372\n",
      "Epoch 21/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1589 - mean_absolute_error: 0.2778 - val_loss: 0.2271 - val_mean_absolute_error: 0.3336\n",
      "Epoch 22/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1581 - mean_absolute_error: 0.2744 - val_loss: 0.2254 - val_mean_absolute_error: 0.3321\n",
      "Epoch 23/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1533 - mean_absolute_error: 0.2720 - val_loss: 0.2257 - val_mean_absolute_error: 0.3382\n",
      "Epoch 24/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1488 - mean_absolute_error: 0.2685 - val_loss: 0.2241 - val_mean_absolute_error: 0.3263\n",
      "Epoch 25/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1471 - mean_absolute_error: 0.2670 - val_loss: 0.2234 - val_mean_absolute_error: 0.3341\n",
      "Epoch 26/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1429 - mean_absolute_error: 0.2644 - val_loss: 0.2255 - val_mean_absolute_error: 0.3321\n",
      "Epoch 27/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1395 - mean_absolute_error: 0.2619 - val_loss: 0.2257 - val_mean_absolute_error: 0.3344\n",
      "Epoch 28/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1368 - mean_absolute_error: 0.2593 - val_loss: 0.2246 - val_mean_absolute_error: 0.3337\n",
      "Epoch 29/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1318 - mean_absolute_error: 0.2551 - val_loss: 0.2296 - val_mean_absolute_error: 0.3420\n",
      "Epoch 30/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1307 - mean_absolute_error: 0.2558 - val_loss: 0.2320 - val_mean_absolute_error: 0.3444\n",
      "Epoch 31/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1274 - mean_absolute_error: 0.2529 - val_loss: 0.2298 - val_mean_absolute_error: 0.3393\n",
      "Epoch 32/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1244 - mean_absolute_error: 0.2500 - val_loss: 0.2272 - val_mean_absolute_error: 0.3325\n",
      "Epoch 33/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1230 - mean_absolute_error: 0.2494 - val_loss: 0.2321 - val_mean_absolute_error: 0.3390\n",
      "Epoch 34/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1203 - mean_absolute_error: 0.2483 - val_loss: 0.2263 - val_mean_absolute_error: 0.3315\n",
      "Epoch 35/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1182 - mean_absolute_error: 0.2457 - val_loss: 0.2264 - val_mean_absolute_error: 0.3332\n",
      "Epoch 36/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1149 - mean_absolute_error: 0.2435 - val_loss: 0.2279 - val_mean_absolute_error: 0.3369\n",
      "Epoch 37/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1140 - mean_absolute_error: 0.2414 - val_loss: 0.2303 - val_mean_absolute_error: 0.3382\n",
      "Epoch 38/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1126 - mean_absolute_error: 0.2403 - val_loss: 0.2338 - val_mean_absolute_error: 0.3354\n",
      "Epoch 39/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1099 - mean_absolute_error: 0.2389 - val_loss: 0.2275 - val_mean_absolute_error: 0.3264\n",
      "Epoch 40/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1078 - mean_absolute_error: 0.2365 - val_loss: 0.2315 - val_mean_absolute_error: 0.3371\n",
      "Epoch 41/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1055 - mean_absolute_error: 0.2334 - val_loss: 0.2257 - val_mean_absolute_error: 0.3329\n",
      "Epoch 42/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1050 - mean_absolute_error: 0.2331 - val_loss: 0.2276 - val_mean_absolute_error: 0.3339\n",
      "Epoch 43/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1031 - mean_absolute_error: 0.2318 - val_loss: 0.2328 - val_mean_absolute_error: 0.3383\n",
      "Epoch 44/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.1029 - mean_absolute_error: 0.2309 - val_loss: 0.2364 - val_mean_absolute_error: 0.3404\n",
      "Epoch 45/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0997 - mean_absolute_error: 0.2272 - val_loss: 0.2303 - val_mean_absolute_error: 0.3377\n",
      "Epoch 46/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0991 - mean_absolute_error: 0.2277 - val_loss: 0.2277 - val_mean_absolute_error: 0.3311\n",
      "Epoch 47/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0985 - mean_absolute_error: 0.2270 - val_loss: 0.2274 - val_mean_absolute_error: 0.3332\n",
      "Epoch 48/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0972 - mean_absolute_error: 0.2251 - val_loss: 0.2326 - val_mean_absolute_error: 0.3413\n",
      "Epoch 49/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0942 - mean_absolute_error: 0.2226 - val_loss: 0.2306 - val_mean_absolute_error: 0.3384\n",
      "Epoch 50/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0939 - mean_absolute_error: 0.2217 - val_loss: 0.2297 - val_mean_absolute_error: 0.3367\n",
      "Epoch 51/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0931 - mean_absolute_error: 0.2207 - val_loss: 0.2350 - val_mean_absolute_error: 0.3367\n",
      "Epoch 52/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0919 - mean_absolute_error: 0.2199 - val_loss: 0.2339 - val_mean_absolute_error: 0.3416\n",
      "Epoch 53/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0900 - mean_absolute_error: 0.2182 - val_loss: 0.2316 - val_mean_absolute_error: 0.3398\n",
      "Epoch 54/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0890 - mean_absolute_error: 0.2160 - val_loss: 0.2322 - val_mean_absolute_error: 0.3374\n",
      "Epoch 55/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0887 - mean_absolute_error: 0.2153 - val_loss: 0.2352 - val_mean_absolute_error: 0.3424\n",
      "Epoch 56/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0873 - mean_absolute_error: 0.2142 - val_loss: 0.2370 - val_mean_absolute_error: 0.3452\n",
      "Epoch 57/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0873 - mean_absolute_error: 0.2138 - val_loss: 0.2402 - val_mean_absolute_error: 0.3497\n",
      "Epoch 58/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0858 - mean_absolute_error: 0.2131 - val_loss: 0.2364 - val_mean_absolute_error: 0.3400\n",
      "Epoch 59/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0848 - mean_absolute_error: 0.2115 - val_loss: 0.2320 - val_mean_absolute_error: 0.3397\n",
      "Epoch 60/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0832 - mean_absolute_error: 0.2113 - val_loss: 0.2399 - val_mean_absolute_error: 0.3368\n",
      "Epoch 61/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0839 - mean_absolute_error: 0.2101 - val_loss: 0.2370 - val_mean_absolute_error: 0.3468\n",
      "Epoch 62/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0824 - mean_absolute_error: 0.2090 - val_loss: 0.2324 - val_mean_absolute_error: 0.3328\n",
      "Epoch 63/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0800 - mean_absolute_error: 0.2069 - val_loss: 0.2351 - val_mean_absolute_error: 0.3408\n",
      "Epoch 64/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.0808 - mean_absolute_error: 0.2078 - val_loss: 0.2364 - val_mean_absolute_error: 0.3439\n",
      "Epoch 65/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.0793 - mean_absolute_error: 0.2050 - val_loss: 0.2407 - val_mean_absolute_error: 0.3472\n",
      "Epoch 66/100\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.0776 - mean_absolute_error: 0.2038 - val_loss: 0.2341 - val_mean_absolute_error: 0.3398\n",
      "Epoch 67/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0795 - mean_absolute_error: 0.2041 - val_loss: 0.2317 - val_mean_absolute_error: 0.3366\n",
      "Epoch 68/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0772 - mean_absolute_error: 0.2023 - val_loss: 0.2410 - val_mean_absolute_error: 0.3432\n",
      "Epoch 69/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0772 - mean_absolute_error: 0.2017 - val_loss: 0.2389 - val_mean_absolute_error: 0.3442\n",
      "Epoch 70/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0760 - mean_absolute_error: 0.1996 - val_loss: 0.2354 - val_mean_absolute_error: 0.3387\n",
      "Epoch 71/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0751 - mean_absolute_error: 0.1993 - val_loss: 0.2406 - val_mean_absolute_error: 0.3432\n",
      "Epoch 72/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0742 - mean_absolute_error: 0.1984 - val_loss: 0.2405 - val_mean_absolute_error: 0.3424\n",
      "Epoch 73/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0741 - mean_absolute_error: 0.1980 - val_loss: 0.2424 - val_mean_absolute_error: 0.3448\n",
      "Epoch 74/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0732 - mean_absolute_error: 0.1974 - val_loss: 0.2354 - val_mean_absolute_error: 0.3370\n",
      "Epoch 75/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0720 - mean_absolute_error: 0.1963 - val_loss: 0.2378 - val_mean_absolute_error: 0.3416\n",
      "Epoch 76/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0719 - mean_absolute_error: 0.1960 - val_loss: 0.2381 - val_mean_absolute_error: 0.3416\n",
      "Epoch 77/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0716 - mean_absolute_error: 0.1944 - val_loss: 0.2365 - val_mean_absolute_error: 0.3378\n",
      "Epoch 78/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0714 - mean_absolute_error: 0.1949 - val_loss: 0.2397 - val_mean_absolute_error: 0.3436\n",
      "Epoch 79/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0699 - mean_absolute_error: 0.1926 - val_loss: 0.2435 - val_mean_absolute_error: 0.3492\n",
      "Epoch 80/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0690 - mean_absolute_error: 0.1916 - val_loss: 0.2383 - val_mean_absolute_error: 0.3434\n",
      "Epoch 81/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0688 - mean_absolute_error: 0.1913 - val_loss: 0.2411 - val_mean_absolute_error: 0.3424\n",
      "Epoch 82/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0672 - mean_absolute_error: 0.1899 - val_loss: 0.2420 - val_mean_absolute_error: 0.3406\n",
      "Epoch 83/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0676 - mean_absolute_error: 0.1901 - val_loss: 0.2407 - val_mean_absolute_error: 0.3440\n",
      "Epoch 84/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0664 - mean_absolute_error: 0.1879 - val_loss: 0.2460 - val_mean_absolute_error: 0.3461\n",
      "Epoch 85/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0662 - mean_absolute_error: 0.1878 - val_loss: 0.2444 - val_mean_absolute_error: 0.3388\n",
      "Epoch 86/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0657 - mean_absolute_error: 0.1880 - val_loss: 0.2493 - val_mean_absolute_error: 0.3538\n",
      "Epoch 87/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0646 - mean_absolute_error: 0.1863 - val_loss: 0.2453 - val_mean_absolute_error: 0.3462\n",
      "Epoch 88/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0649 - mean_absolute_error: 0.1851 - val_loss: 0.2415 - val_mean_absolute_error: 0.3399\n",
      "Epoch 89/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0638 - mean_absolute_error: 0.1837 - val_loss: 0.2449 - val_mean_absolute_error: 0.3435\n",
      "Epoch 90/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0639 - mean_absolute_error: 0.1842 - val_loss: 0.2454 - val_mean_absolute_error: 0.3452\n",
      "Epoch 91/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0630 - mean_absolute_error: 0.1837 - val_loss: 0.2376 - val_mean_absolute_error: 0.3383\n",
      "Epoch 92/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0623 - mean_absolute_error: 0.1810 - val_loss: 0.2411 - val_mean_absolute_error: 0.3380\n",
      "Epoch 93/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0616 - mean_absolute_error: 0.1815 - val_loss: 0.2465 - val_mean_absolute_error: 0.3479\n",
      "Epoch 94/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0617 - mean_absolute_error: 0.1815 - val_loss: 0.2467 - val_mean_absolute_error: 0.3467\n",
      "Epoch 95/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0607 - mean_absolute_error: 0.1803 - val_loss: 0.2522 - val_mean_absolute_error: 0.3575\n",
      "Epoch 96/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0615 - mean_absolute_error: 0.1800 - val_loss: 0.2439 - val_mean_absolute_error: 0.3424\n",
      "Epoch 97/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0614 - mean_absolute_error: 0.1806 - val_loss: 0.2491 - val_mean_absolute_error: 0.3439\n",
      "Epoch 98/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0585 - mean_absolute_error: 0.1779 - val_loss: 0.2475 - val_mean_absolute_error: 0.3475\n",
      "Epoch 99/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0591 - mean_absolute_error: 0.1781 - val_loss: 0.2437 - val_mean_absolute_error: 0.3390\n",
      "Epoch 100/100\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.0578 - mean_absolute_error: 0.1759 - val_loss: 0.2412 - val_mean_absolute_error: 0.3433\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Model Percentage Error: 10.31%\n",
      "mean_absolute_error: 0.3640330872133132\n",
      "explained_variance_score: 0.5743841340667475\n",
      "mean_squared_error: 0.5389050415722751\n",
      "r2_score: 0.5660945434885717\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "[8.75878125e+03 1.41577188e+04 3.53218750e+02 3.00461875e+04\n",
      " 1.73315391e+04 3.63210156e+04 1.32979688e+04 9.69968750e+03\n",
      " 3.23919531e+04 2.68011562e+04 1.24965156e+04 9.93718750e+03\n",
      " 6.20271875e+04 3.07225000e+03 9.35459375e+03 4.08011875e+04\n",
      " 2.68570625e+04 2.83544062e+04 2.14523438e+04 4.69421875e+02\n",
      " 3.65968750e+02 1.42092344e+04 4.30317734e+04 8.45183594e+03\n",
      " 6.86915625e+03 2.61693281e+04 5.74289047e+05 1.34901406e+04\n",
      " 6.03766562e+04 2.65967188e+04 1.67907469e+05 1.02102812e+04\n",
      " 3.49461719e+04 1.41408125e+04 3.47787500e+03 4.21902656e+04\n",
      " 2.29171250e+04 3.37873438e+04 7.88358594e+04 1.70565000e+04\n",
      " 3.72906875e+04 9.41298438e+03 2.54887500e+03 4.29094688e+04\n",
      " 7.72025000e+03 3.98598750e+04 4.17584844e+04 2.29135469e+04\n",
      " 1.30678594e+04 1.34660938e+03 7.81642188e+03 9.75617188e+03\n",
      " 2.25283906e+04 6.11378438e+04 1.11052969e+04 3.28257344e+04\n",
      " 5.59207812e+03 7.54726562e+03 7.64415625e+03 4.97635938e+03\n",
      " 3.11765625e+04 1.10856250e+03 7.24431250e+03 1.21580625e+04\n",
      " 2.13794375e+04 1.33007188e+04 2.93046094e+03 1.60058281e+04\n",
      " 3.78055469e+04 4.68526562e+03 3.91806250e+04 1.76398750e+04\n",
      " 1.56453125e+02 1.62222031e+04 1.63678750e+04 2.08599219e+04\n",
      " 1.23010938e+03 2.13741094e+04 3.56724219e+04 1.68372500e+04\n",
      " 8.35592188e+03 3.59446875e+03 6.14467188e+03 1.32772031e+04\n",
      " 5.08545312e+03 2.43932500e+04 2.25470312e+03 1.62202031e+04\n",
      " 1.71215938e+04 3.39885312e+04 3.39987344e+04 9.75828125e+03\n",
      " 4.30396875e+03 6.89706250e+03 1.91263750e+04 3.13131250e+03\n",
      " 8.90092188e+03 7.55357812e+03 9.02106250e+03 4.83109375e+03\n",
      " 3.97259844e+04 2.98046875e+02 1.68379844e+04 6.10357812e+03\n",
      " 1.61359375e+03 3.40172969e+04 1.27270156e+04 7.68018438e+04\n",
      " 2.79924375e+04 4.36307812e+03 1.46296641e+04 5.56062500e+03\n",
      " 4.43741719e+04 2.69007344e+04 1.24435312e+04 1.43541719e+04\n",
      " 1.24034375e+03 1.09643125e+04 4.71993594e+04 4.88036406e+04\n",
      " 1.66117188e+03 4.48731406e+04 2.65167500e+04 2.11576875e+04\n",
      " 2.50255391e+04 3.13804688e+04 3.77909688e+04 5.78675938e+04\n",
      " 4.52730469e+04 5.33321875e+03 1.45050312e+04 4.52981562e+04\n",
      " 3.78112812e+04 1.62902969e+04 1.81026609e+05 3.49960781e+04\n",
      " 7.26398438e+03 2.96326094e+04 1.00691250e+04 1.36253438e+04\n",
      " 9.78734375e+02 3.26303281e+04 8.22473438e+03 1.80753125e+03\n",
      " 1.52084062e+04 1.00815625e+04 2.62072500e+04 1.91084375e+03\n",
      " 1.05301406e+05 7.05253906e+03 2.17804688e+04 3.05607500e+04\n",
      " 5.66210938e+02 2.42280469e+03 1.84745312e+04 5.13362344e+04\n",
      " 2.38600312e+04 3.44625781e+04 1.37648438e+04 3.73520312e+03\n",
      " 4.74097656e+04 8.51853125e+03 2.91730469e+04 3.90831406e+04\n",
      " 1.45178281e+04 1.32274375e+04 2.42603125e+03 1.57270000e+04\n",
      " 5.40614062e+03 1.77771719e+04 2.14521250e+04 1.70819219e+04\n",
      " 6.00234844e+04 3.90547656e+04 2.17570312e+04 7.90467188e+03\n",
      " 4.67379844e+04 5.78787500e+03 3.23509375e+03 1.76938438e+04\n",
      " 6.24827500e+04 4.52791875e+04 1.93608125e+04 2.38790938e+04\n",
      " 3.93858750e+04 1.23225469e+04 1.08221719e+04 1.66998125e+04\n",
      " 2.04178594e+04 3.11446562e+04 1.04023984e+04 4.29832812e+04\n",
      " 8.25043750e+03 1.33946562e+04 2.21248438e+03 1.40862969e+04\n",
      " 1.37446875e+03 4.57157812e+03 4.24217812e+04 1.58959375e+04\n",
      " 3.22651562e+03 1.11345312e+04 1.97430000e+04 3.41192656e+04\n",
      " 5.91331250e+03 8.25476562e+03 2.75090469e+04 2.65775312e+04\n",
      " 4.26449219e+04 5.55134219e+04 3.25652656e+04 1.00582656e+04\n",
      " 1.83362969e+04 4.03010625e+04 2.80052188e+04 1.01455938e+04\n",
      " 1.17950625e+04 4.43789844e+04 3.91827969e+04 2.80750781e+04\n",
      " 1.45385156e+03 9.88407812e+03 2.64697344e+04 1.25797188e+04\n",
      " 5.92957812e+03 1.76420312e+04 6.53723750e+04 6.30843750e+02\n",
      " 3.66568438e+04 4.57327500e+04 2.32251562e+03 7.91284375e+03\n",
      " 3.08527344e+04 9.74329688e+03 1.44715312e+04 1.91714062e+03\n",
      " 1.20142500e+04 8.22450781e+04 4.07463594e+04 1.03684531e+04\n",
      " 1.29748594e+04 1.70510000e+04 1.21506875e+04 3.41382812e+03\n",
      " 2.07107812e+03 1.33427812e+04 5.69272344e+04 1.99492188e+04\n",
      " 1.89863750e+04 2.72085000e+04 2.16859375e+02 2.07109375e+02\n",
      " 4.50255781e+04 1.22496094e+04 4.09593750e+03 1.35072656e+04\n",
      " 4.89881406e+04 1.65888594e+04 8.20606250e+03 6.70129688e+03\n",
      " 1.86840781e+04 1.93536562e+04 1.17406719e+04 4.68725938e+04\n",
      " 1.75763906e+04 1.16728594e+04 4.41261719e+03 1.46609375e+04\n",
      " 2.05718750e+04 4.27032500e+04 1.33104531e+04 1.86875000e+03\n",
      " 6.87125469e+04 1.72077500e+04 4.21515000e+04 2.07321406e+04\n",
      " 2.27267188e+03 1.62043906e+04 4.50892188e+03 1.34491875e+04\n",
      " 4.03454688e+04 5.50852656e+04 7.59139844e+04 4.90081094e+04\n",
      " 1.28693750e+04 5.41839062e+03 2.40836094e+04 2.30290625e+03\n",
      " 2.92612812e+04 6.09864688e+04 4.61181875e+04 1.13107344e+04\n",
      " 2.45665938e+04 3.17904531e+04 2.12356250e+03 2.78677656e+04\n",
      " 1.17284219e+04 1.14376562e+04 2.22820000e+04 5.73993750e+03\n",
      " 2.53467031e+04 2.65588594e+04 3.38259375e+03 7.85664062e+03\n",
      " 3.97852969e+04 3.35796250e+04 5.76413438e+04 1.45380000e+04\n",
      " 2.24231562e+04 1.10590625e+04 1.41757812e+04 8.62946875e+03\n",
      " 1.37891328e+04 5.13104375e+04 1.23687188e+04 4.29661406e+04\n",
      " 2.23690469e+04 8.84968750e+03 4.82715000e+04 2.50385312e+04\n",
      " 2.04285469e+04 5.65750156e+04 4.68403594e+04 4.51931406e+04\n",
      " 2.60175625e+04 9.70937500e+01 3.08656250e+03 5.45759062e+04\n",
      " 2.65253438e+04 2.08065156e+04 3.22903438e+04 4.97936250e+04\n",
      " 6.40439062e+03 1.10488438e+04 3.25679062e+04 1.53715000e+04\n",
      " 2.63939531e+04 1.26070781e+04 1.78498438e+04 6.82262500e+03\n",
      " 7.55679688e+03 9.50291484e+04 1.59280469e+04 2.25874219e+04\n",
      " 2.67673750e+04 4.93141719e+04 2.32991562e+04 1.65570938e+04\n",
      " 2.81475000e+03 1.27719062e+04 1.14925625e+04 4.22738438e+04\n",
      " 2.59870469e+04 1.78016562e+04 2.85643438e+04 1.99902500e+04\n",
      " 2.09235938e+03 1.21486406e+04 2.81706719e+04 8.70940625e+03\n",
      " 1.07206875e+04 4.50356719e+04 2.32399688e+04 4.87993750e+03\n",
      " 5.34309062e+04 1.68181562e+04 4.33156250e+02 3.79250156e+04\n",
      " 9.47809375e+03 2.11336719e+04 3.01077188e+04 6.85870938e+04\n",
      " 3.96990781e+04 9.15740312e+04 2.14241562e+04 1.19786719e+04\n",
      " 2.17636875e+04 4.27874844e+04 1.04023281e+04 3.34018281e+04\n",
      " 3.50002969e+04 1.78559844e+04 5.20023438e+03 1.66642188e+03\n",
      " 4.92064531e+04 4.11700000e+03 1.12811875e+04 2.57246719e+04\n",
      " 3.42965000e+04 1.58987500e+04 1.35379688e+03 2.73853125e+03\n",
      " 3.62065625e+03 2.67452656e+04 6.51326562e+03 1.08635156e+04\n",
      " 5.28626172e+04 1.92581094e+04 3.36871406e+04 3.34538281e+04\n",
      " 1.21795312e+03 3.04624531e+04 1.36267188e+04 4.11776875e+04\n",
      " 1.36631875e+04 3.44792500e+04 5.37129531e+04 2.96382500e+04\n",
      " 5.55153125e+03 4.33051875e+04 4.17512344e+04 4.04762500e+03\n",
      " 1.31474062e+04 1.75309375e+03 3.83073438e+03 1.99899531e+04\n",
      " 1.95104062e+04 2.40890000e+04 6.45512500e+03 3.42805000e+04\n",
      " 8.82918750e+03 3.35315625e+03 7.77987500e+03 1.65671406e+04\n",
      " 3.57720625e+04 5.12206875e+04 1.42171875e+02 4.78376719e+04\n",
      " 5.19367500e+04 1.07867500e+04 7.27381250e+03 4.31556250e+03\n",
      " 4.85479688e+03 5.18555000e+04 3.24337812e+04 2.35528438e+04\n",
      " 2.93862188e+04 2.77326719e+04 8.59798438e+03 2.58182812e+03\n",
      " 1.14733438e+04 2.45739219e+04 3.14979688e+04 7.21450781e+03\n",
      " 2.03701875e+04 2.97354688e+04 2.65035781e+04 1.14356719e+04\n",
      " 2.66937266e+04 8.53262500e+03 6.34956250e+03 1.58256094e+04\n",
      " 2.12669062e+04 1.41134531e+04 1.02631562e+04]\n",
      "Model Percentage Error: 12.28%\n",
      "mean_absolute_error: 0.4616182920035799\n",
      "explained_variance_score: 0.4440808489803255\n",
      "mean_squared_error: 0.6221317739105278\n",
      "r2_score: 0.4204329449133448\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1+klEQVR4nO3dd3xUdbr48c+TSSa9FyAJJfTeQRRUFHVBBQQL2NburldX3fZbt7rr3b3r3rvXdXevu3bXjogNXRQbiA0EpPcOKZBGep98f398J5CEJATIZJKc5/16zSuZM+ecec6cmfOcbznfI8YYlFJKOVeAvwNQSinlX5oIlFLK4TQRKKWUw2kiUEoph9NEoJRSDqeJQCmlHE4TgVJKOZwmAqVaICL7RaRKRBIaTV8nIkZE+tSb9lvvtLMazXuziHhEpKTRI7mdNkOpFmkiUOrk9gHX1j0RkRFAWP0ZRESA7wL53r+NfW2MiWj0yPRl0Eq1liYCpU7uRRoe3G8CXmg0z7lAD+BeYL6IuNspNqXOmCYCpU5uJRAlIkNExAXMB15qNM9NwLvAQu/zme0Yn1JnRBOBUq1TVyq4GNgGZNS9ICJhwNXAK8aYamARJ1YPTRKRgnqPPe0Ut1InFejvAJTqJF4EVgBpnFgtNAeoAZZ4n78MfCwiicaYHO+0lcaYKe0SqVKnSEsESrWCMeYAttH4UuDNRi/fBEQAB0XkMPA6EARc165BKnWatESgVOvdBsQaY0pFpO63kwJMA2YAG+vNez+2euiv7RqhUqdBE4FSrWSMaape/1xgvTHmw/oTReRvwI9FZLh30tkiUtJo2QuMMat9EKpSp0T0xjRKKeVs2kaglFIOp4lAKaUcThOBUko5nCYCpZRyuE7XayghIcH06dPH32EopVSnsnbt2lxjTGJTr3W6RNCnTx/WrFnj7zCUUqpTEZEDzb2mVUNKKeVwmgiUUsrhNBEopZTDdbo2AqVU11JdXU16ejoVFRX+DqVLCAkJITU1laCgoFYvo4lAKeVX6enpREZG0qdPH+wdP9XpMsaQl5dHeno6aWlprV5Oq4aUUn5VUVFBfHy8JoE2ICLEx8efculKE4FSyu80CbSd0/ksHZMIVu/P589Ld+Cp1dFWlVKqPsckgnUHj/J/y3ZTXu3xdyhKqQ6koKCAf/zjH6e83KWXXkpBQUHbB+QHjkkEoW7bLl5WVePnSJRSHUlziaCmpuVjxZIlS4iJifFRVO3LMb2GQoNcAFRU1fo5EqVUR/LAAw+wZ88eRo8eTVBQECEhIcTGxrJ9+3Z27tzJFVdcwaFDh6ioqOC+++7jzjvvBI4Pd1NSUsKMGTOYMmUKX331FSkpKbzzzjuEhob6ectaz3GJQKuGlOq4fvfuFrZmFrXpOocmR/HgzGHNvv7www+zefNm1q9fz/Lly7nsssvYvHnzse6Xzz77LHFxcZSXlzNhwgSuvPJK4uPjG6xj165dvPrqqzz11FNcc801vPHGG9xwww1tuh2+5JhEEOa2iUCrhpRSLZk4cWKDPvh/+9vfeOuttwA4dOgQu3btOiERpKWlMXr0aADGjRvH/v372yvcNuGYRBCiJQKlOryWztzbS3h4+LH/ly9fzscff8zXX39NWFgYU6dObbKPfnBw8LH/XS4X5eXl7RJrW3FQY7G3jUATgVKqnsjISIqLi5t8rbCwkNjYWMLCwti+fTsrV65s5+jah2NKBMerhjQRKKWOi4+PZ/LkyQwfPpzQ0FC6det27LXp06fz+OOPM2TIEAYNGsSkSZP8GKnvOCYRHGss1kSglGrklVdeaXJ6cHAw77//fpOv1bUDJCQksHnz5mPTf/KTn7R5fL7mmKqhujYCrRpSSqmGHJMItGpIKaWa5phEoL2GlFKqaY5JBK4AwR0YoG0ESinViGMSAdjqIS0RKKVUQ45KBKFBLi0RKKVUI85KBG4XZVoiUEqdgYiICAAyMzO56qqrmpxn6tSprFmzpsX1PProo5SVlR177s9hrZ2VCIJcVGiJQCnVBpKTk1m0aNFpL984EfhzWGvHJQJtI1BK1ffAAw/w2GOPHXv+29/+lt///vdMmzaNsWPHMmLECN55550Tltu/fz/Dhw8HoLy8nPnz5zNkyBDmzJnTYKyhu+66i/HjxzNs2DAefPBBwA5kl5mZyQUXXMAFF1wA2GGtc3NzAXjkkUcYPnw4w4cP59FHHz32fkOGDOGOO+5g2LBhXHLJJW02ppFjriwGWzVUXKGjjyrVYb3/ABze1Lbr7D4CZjzc7Mvz5s3j/vvv5+677wZg4cKFLF26lHvvvZeoqChyc3OZNGkSs2bNavZ+wP/85z8JCwtj27ZtbNy4kbFjxx577Q9/+ANxcXF4PB6mTZvGxo0buffee3nkkUdYtmwZCQkJDda1du1annvuOVatWoUxhrPOOovzzz+f2NhYnw137bgSgV5ZrJSqb8yYMWRnZ5OZmcmGDRuIjY2le/fu/OIXv2DkyJFcdNFFZGRkcOTIkWbXsWLFimMH5JEjRzJy5Mhjry1cuJCxY8cyZswYtmzZwtatW1uM54svvmDOnDmEh4cTERHB3Llz+fzzzwHfDXftuBKBVg0p1YG1cObuS1dffTWLFi3i8OHDzJs3j5dffpmcnBzWrl1LUFAQffr0aXL46ZPZt28ff/7zn1m9ejWxsbHcfPPNp7WeOr4a7tpRJYIwt0uHmFBKnWDevHksWLCARYsWcfXVV1NYWEhSUhJBQUEsW7aMAwcOtLj8eeedd2zgus2bN7Nx40YAioqKCA8PJzo6miNHjjQYwK654a/PPfdc3n77bcrKyigtLeWtt97i3HPPbcOtPZGjSgQh2mtIKdWEYcOGUVxcTEpKCj169OD6669n5syZjBgxgvHjxzN48OAWl7/rrru45ZZbGDJkCEOGDGHcuHEAjBo1ijFjxjB48GB69uzJ5MmTjy1z5513Mn36dJKTk1m2bNmx6WPHjuXmm29m4sSJANx+++2MGTPGp3c9E2OMz1buC+PHjzcn65/bnP/+YDtPrtjL7v+6tI2jUkqdrm3btjFkyBB/h9GlNPWZishaY8z4pub3adWQiEwXkR0isltEHmhmnmtEZKuIbBGRpgcFbyNhbhc1tYaqmlpfvo1SSnUqPqsaEhEX8BhwMZAOrBaRxcaYrfXmGQD8HJhsjDkqIkm+igcajkDqDnRU84hSSjXLl0fDicBuY8xeY0wVsACY3WieO4DHjDFHAYwx2T6MR+9brFQH1dmqqDuy0/ksfZkIUoBD9Z6ne6fVNxAYKCJfishKEZne1IpE5E4RWSMia3Jyck47IL05jVIdT0hICHl5eZoM2oAxhry8PEJCQk5pOX/3GgoEBgBTgVRghYiMMMYU1J/JGPMk8CTYxuLTfTO9b7FSHU9qairp6emcyUmeOi4kJITU1NRTWsaXiSAD6Fnveap3Wn3pwCpjTDWwT0R2YhPDal8EpHcpU6rjCQoKIi0tzd9hOJovq4ZWAwNEJE1E3MB8YHGjed7GlgYQkQRsVdFeXwUU5rZ5T0sESil1nM8SgTGmBrgHWApsAxYaY7aIyEMiMss721IgT0S2AsuAnxpj8nwVU6iWCJRS6gQ+bSMwxiwBljSa9pt6/xvgR96Hz4W6bd7TRKCUUsc5qjN96LGqIR2KWiml6jgrEWivIaWUOoEzE0G1DjGhlFJ1HJUIQoK8bQRaNaSUUsc4KhGIiN63WCmlGnFUIgC9S5lSSjXmvEQQpHcpU0qp+pyXCNx6A3ullKrPeYlASwRKKdWA8xKB26XXESilVD3OSwRBWjWklFL1OTIRaNWQUkod57hEEKbdR5VSqgHHJYIQ7TWklFINOC4RaNWQUko15LhEUFc1pDfKVkopy3GJICTIhTFQWaMjkCqlFDgwEeg9CZRSqiHHJYIwt963WCml6nNcIgjVRKCUUg04LhGEaNWQUko14LhEoFVDSinVkOMSgTYWK6VUQ45LBHVVQ3pRmVJKWY5LBHVVQzrMhFJKWY5LBNprSCmlGnJeItCqIaWUasB5iUCrhpRSqgHHJQK3K4AA0V5DSilVxzmJYOdSWHQrYowORa2UUvU4JxEc3Q+b34CyPELdgdpYrJRSXj5NBCIyXUR2iMhuEXmgiddvFpEcEVnvfdzus2Ciku3fogxC3QHaRqCUUl6BvlqxiLiAx4CLgXRgtYgsNsZsbTTra8aYe3wVxzHHEkEmoUHhlFXV+PwtlVKqM/BliWAisNsYs9cYUwUsAGb78P1aFpVi/xZnequG9MY0SikFvk0EKcChes/TvdMau1JENorIIhHp2dSKROROEVkjImtycnJOL5rwRAgI9JYIAijXEoFSSgH+byx+F+hjjBkJfAQ839RMxpgnjTHjjTHjExMTT++dAlwQ0R2KMgnTxmKllDrGl4kgA6h/hp/qnXaMMSbPGFPpffo0MM6H8dh2gqIMQoNceh2BUkp5+TIRrAYGiEiaiLiB+cDi+jOISI96T2cB23wYjzcRZBKiiUAppY7xWSIwxtQA9wBLsQf4hcaYLSLykIjM8s52r4hsEZENwL3Azb6KB7ANxkVZhAUFaNWQUkp5+az7KIAxZgmwpNG039T7/+fAz30ZQwNRPaC6lBhXuSYCpZTy8ndjcfvyXkuQUJtLRXUttbXGzwEppZT/OSwR2N6rCbW5AFTUaKlAKaUclghsiSCmxiYCbTBWSimnJYKI7oAQ600EBeXV/o1HKaU6AGclgkA3hCeSiE0E+3NL/RyQUkr5n7MSAUBUMjHVdpiKPTklfg5GKaX8z4GJIIWg0sPEhbvZm6MlAqWUcmAisFcX900I10SglFI4MhH0gIoCBsUHsDdXq4aUUsqBicBeSzA8sozckioKteeQUsrhHJgI7LUEA0IKAdirDcZKKYdrVSIQkftEJEqsZ0TkWxG5xNfB+YS3RNAzqC4RaDuBUsrZWlsiuNUYUwRcAsQCNwIP+ywqX4q0I18neHIJDBBtJ1BKOV5rE4F4/14KvGiM2VJvWufiDoOQGFwlWfSKC2NPtpYIlFLO1tpEsFZEPsQmgqUiEgl03ru/R6XYLqSJ4VoiUEo5XmvvR3AbMBrYa4wpE5F44BafReVr3ltW9u0ZwYpduXhqDa6AzlnAUUqpM9XaEsFsYI8xpsD73AP09UlE7SEqGYqy6JsQTlVNLRlHy/0dkVJK+U1rE8GDxpjCuifehPCgTyJqD1HJUJpNvzg3AHu0ekgp5WCtTQRNzefT21z6VHQqAP3d+YB2IVVKOVtrE8EaEXlERPp5H48Aa30ZmE91HwlATOFWokOD9KIypZSjtTYR/ACoAl7zPiqBu30VlM8lDQFXMJK5jr6J4ToctVLK0VpVvWOMKQUe8HEs7ccVBN1HQOZ6+iZcw+e7cvwdkVJK+U2LJQIRedT7910RWdz40S4R+kryGMhaT9+EULKLKymu0MHnlFLOdLISwYvev3/2dSDtLnkMrH6KUaG2NLD9cDET+sT5OSillGp/LSYCY8xaEXEBdxpjrm+nmNpH8hgAxgbuxxUQy4qdOZoIlFKOdNLGYmOMB+gtIu52iKf9JAyEoDDCcjcxtlcMy3Zk+zsipZTyi9ZeC7AX+NLbLnCs070x5hGfRNUeXIG2G2nmOqYOup3/WbqD7OIKkiJD/B2ZUkq1q9Z2H90DvOedP9L7iPBVUO0meQwc3sjUAbEAfLZDew8ppZyntSWCrcaY1+tPEJGrfRBP+0oeA6v+ydCgwyRFBrN8Zw5Xj+/p76iUUqpdtbZE8PNWTutcvA3GkrmeqYMS+XxnDjWezju6tlJKnY4WSwQiMgN7D4IUEflbvZeigBpfBtYu4vuDOxIy13HBoAtZuCaddYcKtPeQUspRTlYiyATWABXYsYXqHouB7/g2tHYQEADJoyFzHZMHJBAYICzbrr2HlFLO0mIiMMZsMMY8D/QHFgIrjTHPG2PeNMYcPdnKRWS6iOwQkd0i0uwQFSJypYgYERl/yltwppJHw+FNRAXBuN6xLNcGY6WUw7S2jWA6sB74AEBERp9siAnvhWiPATOAocC1IjK0ifkigfuAVa0Puw2ljANPJWz/N1MHJbE1q4gjRRV+CUUppfyhtYngt8BEoADAGLMeSDvJMhOB3caYvcaYKmAB9k5njf0n8Cds9VP7G3QZ9BgN793P9F4eAN7bmOWXUJRSyh9amwiq69+hzMucZJkU4FC95+neaceIyFigpzHm3y2tSETuFJE1IrImJ6eNq24C3XDl01BTSdrnP2F0ahQLVx/CmJNtnlJKdQ2tTQRbROQ6wCUiA0Tk78BXZ/LGIhIAPAL8+GTzGmOeNMaMN8aMT0xMPJO3bVrCAJj+MOz7jAfjP2XHkWLWHypo+/dRSqkO6FRuTDMMe0OaV4BCbL1+SzKA+ldnpXqn1YkEhgPLRWQ/MAlY7JcGY4Cx34UhMxm96+8MD8pi4ZpDJ19GKaW6gNYmgqHeRyAQgq3rX32SZVYDA0QkzTtg3Xxst1MAjDGFxpgEY0wfY0wfYCUwyxiz5hS3oW2IwOV/RVxBPBj/Me9uyKKsqvNfKqGUUifT2kTwMvAsMBe43PuY2dICxpga4B5gKbANWGiM2SIiD4nIrNMP2YfC42HMjYwr+piwyhz+rY3GSikHaO1YQznGmHdPdeXGmCXAkkbTftPMvFNPdf0+MekuZPVT3B/1Ka+t7qtjDymlurzWlggeFJGnReRaEZlb9/BpZP4Sl4YMmcWVtUvZdiCT3dnF/o5IKaV8qrWJ4BZgNPbCspnex+U+isn/zvkBwTUl3OD+jD99sMPf0SillE+1tmpogjFmkE8j6UhSx0Ovc7jnyIeM3noxn24/woWDu/k7KqWU8onWlgi+amp4iC7tnB8QWXmYH0Z/xm8Xb6Wi2uPviJRSyidamwgmAeu9A8htFJFNIrLRl4H53cDpMOAS/qP6BaKPbuaJz/b6OyKllPKJ1lYNTfdpFB1RQADMeYKAx8/luYD/Y8by7swZk0Kv+LCTL2sMvHMPRCXDhb/0faxKKXUGWlUiMMYcaOrh6+D8LiwOrv4X8bW5/NH1OH96f1vrltvyJqx/CVb+A6pKfRujUkqdodZWDTlXzwnIxf/JRbKGi3b8mvU797c8f/lReP9nENENqkpgx/vtEqZSSp0uTQStMekuqs79GTNdX9NzwYWY3Z80P+9Hv4GyfLhuIUSlwMaF7RenUkqdBk0ErSGCe9ov+HTyK+TXhCAvzYVX5sGuj6C23s3u938B374AZ99t73w2/ErY8wmU5vktdKWUOpnWNhYrYNq06czeFMTc8te5JeNTZOdVENMbIrtDwSEozrLPp3rvyjnyGvjqb7bNYOId/g1eKeVfG1+Hb5+H614Dd7i/o2lASwSnwBUg/OSykTxUPIt/jH4HrnoW4vuDyw39LoDzfgo3vHl8J3cbDklDYdPr/g1cKXUiY2DHB1DR+J5bPpCzExb/APZ/Dt885fv3O0VaIjhF5w9MZOaoZP73032Mue18zrnxyuZnFoERV8Mnv4Oj+yG2T3uFqZQ6mW2LYeF3occouPFt20vQF2qq4M3bISjEvteXf4UJt0FwpG/e7zRoieAUiQgPzx1B38QIfvDqOrIKy1teYMRV9q+WClRrGQObFtl2qKP7/R1Nx7DzQ9v+1la3kK2theUPQ2QPyN4GL8y2nTzaSm29kQiW/xdkbYBZf4fv/BeU58OqJ9ruvdqAJoLTEB4cyOM3jKWi2sPdL39LVU1t8zPH9II+58JXf4cDX7dfkKpzyt4Gz8+EN26DnR/AazdA9UlONsAe2L5+DHJaOUhi9nb490/gowcbHrQ6mupyeO+H8MrVtmrl1WtP/YBdlAkHvmrYsWPr25C9FS75Pcx/1X5uz8+C0twzi9cYePs/4D8T4W9j4KWr4ItHYcyNMGQmpI6zoxZ89XeoKGq4bGkefPp7eGySjbcdSWe7Sfv48ePNmjX+uYlZY+9tzOSeV9Zx/Vm9+P0VwxGRpmc8egBemguF6XDVczD40vYNtD2U5sGOJfbHNeF2iO/n74g6j5pK2LkUNr5mrzsJiYJpv7Fnq6/Oh1HXwRX/sFWNzfn8EVsF2WMU3LHcXhnfmKcGdi21ddR7l0FAENRWw4hr4Ip/gquJmuJaD2SusyWTggP2YHrWnRAS3XC+wgxwh0FIjH1+ZIvdlv2fw+R7of9Fp/65HNkKi26FnG1wzr32Sv0Pf207Z1z2CKSMhbD4pj+XnB2w/mXY/Qkc2WynjZwPsx+z8//jbJAAuOtLCHDB7o9hwfV23de+BkmDj68rawPs/QzSV0PWeuh1Nsz8KwSFnvi+X/8Dlv4chs0FUwu5O8EdATe+BcERdp7MdfDkVLjglzD+VrvOXR/bhuTqMgiNtcveuhSShhxfd/pa+9zditENmiAia40xTd4KWBPBGXr4/e08/tkefnXZEG4/t2/zM5bmwivX2C/BtAdh9HUQkWRfy90Fq5+2P7ZZfz8+vTPI3gZLfgoHvrRfXgkAVzBc/DuYcEfTB6SOwpiWD66N7f/S1iPX/3G2ZM+n9sy751nQYyS4ghq+7qmBlY/B5/9rGyzDk2xPsyk/snfLA1j2R/jsYbjsf22Cbcq+z+GFWRDXD/J2wZXPHK+SBCjKgrXPwbcvQnEmRCbDxNth7M3w7b/gk4dg6GyY+zQEuo8vV15g69D3fdbw/WJ62/foOQHy9sDSX8JO74WTrmDbWaLce9YeGgtVZXDtK8eTQU2VvfK+sN4tzHueBQMuPr4/1r8C7/3I1qPPeRz6T7PTM9bC67fYpATgjoSEAdBzol2HOxy+edIe2AOCoNcku97yAvjiERh6BQz8Drx9F1z9PAy74ngM6WtsiaOmwp6wBbphxZ+Pb39Mb0gcDLs+tOu99lW7fXUOfA3PX27P+Oe91PJ369Xr7IkT3uOvuOy+n3y/PdA/fbFNULd9BLU1NslvfgMufggmn+x28U3TROBDtbWGu1/5lg+2HOaJG8ZxybDuzc9cWQKLbrFfJARSJ9izin2f2S9tgMue9dz4NsT29m3g1RX2oF3/h3+q8vfCs9NtAhh3sy36hiXAu/fB7o+g9xS46hl7llWn1mO/0GnnQ2QrhvY2Bkqy7Y/jTBvXjIFDq+xBYvcncHgTpJ1rG/QHX27PxJvz7Yuw+B77f/IYGH29XSaqx4nzluTABz+z21knKBx6nw2DZsDAGfZA+c499mxw4HTbvTht6oln5bW18Oo8G29cGgSG2jPLftNg9LUQEAiPn2vP0O/4BP51mU0q96yBwGCbqJ+71F7x3n+a3U8DpzdMSl8/Bkt/Ab0n2yTU70IoSoeXr7GJ5ZI/QN/zbTXn4c224bMwA4Zcbs/6XW44+x77+RUftu+VOsEecF1uW+WStwuuXWC/K+//P8jbbQ9+YKdh7Od63k9tldi3L9gq1SufOfF7Ullsk/LRfZC/z5ZC09dAjbcKLaKbPQkZfwuEJxxf7qv/gw9/ab/3SUPhe5+feKJScMgmgyObjq/r7Htg1PzjJ2ib34S3vgdxfe2JW2icPVi/MNt+T+9cfmKJqbG8PfDlo5Aw0Jbiuo+E0Jjjr2dttPstJBpKc2zM5/zAJoG6ksUp0kTgY+VVHuY/tZKdh4tZ+L2zGZHawpfAGFtU3fE+bP83VBTAmBtg7E22RPDy1TY5zH/FHjSz1tsvTYDL/njdETDgEug+oukzjrJ8+6PuNsz+6Js6eO7/El6/yf4Ybnz79M7ai7Lg2e9AZRHc8kHDorQxsO4lO9RGWDzcsAgSB9kf8Bu32x96XF+46T2ITml6G1Y/Y6sVjmyGsjwIDLGJZvR1NokEuBous+sj+3lOvs8eMBtLXwMf/BzSv7E/qtQJtnvv7o/t2WVgKFz6PzD2xhOX3bTIxt3vAuh/sa1yqKtuiO5p1xWdag9otR7YuMAm/fN+auPNWGM/8z2f2OQJNoaweLj0z/ZsvKWzx/Kj8Nl/Q8kRW2dekm3XiUB4oh3K5I5PbUll9ye2GvI7f7QH4udm2Pm++07DfdTYty/as87SHNu7rarMVlnNe9EmgfoqCm29/eY3YNS1cNFvGyb7xkrzbLtH7g57wIzrCzP+256pA3iqYcMCWPE/x8/0z/0xTP1F09VVTfFU24NnaY7dT4HBTc/3zVP29zHvJfv5NKWyBJb9F8T3hdE32N4+je37HBZcZ7//dQJD4faPofvw1sV8MnuXw4IbYPBlMO3X9jt2BjQRtIPs4grmPPYVFdUeXv/+2fRNPL2szZGt8OIcKDl8fFpQuD1QeKrsAyBhkD2THXfT8TOVwnR4ca49+zK19mxiwh22+Js42J49rnrCnhWFRNsD7OWP2jOnOhlrIeNbe3aYNMS+b94ee/DO3WUPXuGJsPZfUHgIvrvYNoA1JXOdPav0VMHlf7FVINnb4Jx7YM1ztprlpvcgxntf6OLDdqC+1c/Yg1uP0TbhdRtmzyA3vW4PQqkT7YGtrq706AF4fIr9UQYE2bPrs75vz7rz99ki+KbX7dnd1J/bz6OuSG+MTRLLfm9/eOf+BC781fED8/Z/2+qR1Ilwwxv2PY2xpYn9n9t640Or7WcpAoi9qvyyR0488Bpj64x3LLHbcc69p99lMX8fbHgVtr0L5/3EXsVe54XZtl7bHWk/x1vebzkJ1Kmpsl0q1zxrk828F5uvBjPGJqjWxl+aa0tAqePg7B80fXD1VNuz7YgkezD3leqKpt//VBWmQ+Z6W69fXWZLND1Gnfl66zvV6ssWaCJoJ3tySrjm8a8JCXLx+vfPJjmmicak1ig4CFvetg2uPUbZMYvqvgxl+bbHw6ZFtl4+MMSWJgZfansrVBbbusvAUPjyL7DtPcDYutvoVMjfA4Mugzn/tD1SMtfD3atsldTuT2yx2FNp3ys8yRZD685iQ2PtAczU2ve9buGJZ4uNHd1ve07k7YLgKLj6OVtXnL4WXppjE1LvyXDoGxubBNiD2pQfQbdG90KqroAN3rrjITNtHS/GVocc3mxLHutesmfspl4PkcAQW7yfcn/z1Uueavj3j2yVxNDZth5998c27uSxNvG0VHXUkWRtgCfOs5/3Te/axKQcTxNBO9qcUci1T64kMSqY1793NvERzRRR20LuLvjiL7a3SW2NPeO94Q17Fl2n4KA9yGZtsD05+p5vz8gCAuwB/h/n2Drhs75nG7Pj+9vGucz1tu2iosgeuAdeYqsMamvtmaAr8OT1oHXK8m2co69veGaauQ5emQ/GY8+4U8fbg/DJehx99Xf48Fc2WbjDbJe7OU/CqHn29SNbYd8KW+0Um2arilpzSb8xNs5PfmeTR58pdttHX9f6be0o6k4k6n8XlKNpImhn3+zL58ZnVjGgWwSv3jGJyJCgky90JgoO2mQw4upTv3r5y7/BR7+2VSrx/eHm9xo2sPlaba0t7ZxK8dcY2yD97fO2BDFsLlz5dJsVoSnKsg13TXUPVKqT0kTgB8u2Z3PHC2sY2zuWF26dSEiQ6+QL+YOnBv51qa3yuendztN11VNt+9jn74U7ljXscaGUOoEmAj95Z30G97+2ngsHJfH4jeMIcnXQPvWeantm3bgnTkdnjI39TLrAKuUQLSWCDnpk6hpmj07hP2cP55Pt2dz10lpyiiv9HVLTXEGdLwmArQrSJKDUGdNE4GM3TOrNgzOHsmJnLtP+dzmvfnOQ2trOVQpTSnVtmgjawS2T01hy37kM6RHFz9/cxHVPryS3pIOWDpRSjqOJoJ30T4pgwZ2T+NOVI1h/qIBZf/+CzRntcEMMpZQ6CU0E7UhEmDehF4u+fw4AVz3+Fe+szzjJUkop5VuaCPxgeEo0i38whZEpMdy3YD1/XLINj7YbKKX8xKeJQESmi8gOEdktIg808fr3RWSTiKwXkS9EZGhT6+mKEiKCeen2s/ju2b15YsVebn7uGwrKqvwdllLKgXx2HYGIuICdwMVAOrAauNYYs7XePFHGmCLv/7OA/zDGTG9pvZ3pOoLWem31QX799haiQoOYMbw7Fw5O4ux+8R33IjSlVKfT0nUEvrx5/URgtzFmrzeIBcBs4FgiqEsCXuEcu0uDs8yb0ItB3aN4bNlu3vg2nRdXHiAyJJDfXD6Uq8alNn/nM6WUagO+TAQpwKF6z9OBsxrPJCJ3Az8C3MCFTa1IRO4E7gTo1atXmwfaEYzuGcNT3x1PZY2HVXvzeWzZbn66aCMfbD7MH+eOICmqDYbNVUqpJvi9sdgY85gxph/wM+BXzczzpDFmvDFmfGJiYvsG2M6CA12cNzCRV++YxG8uH8oXu3O55NEVrNyb5+/QlFJdlC8TQQbQs97zVO+05iwArvBhPJ1KQIBw6xR7IVpCRDDffeYb3tuY6e+wlFJdkC8TwWpggIikiYgbmA8srj+DiAyo9/QyYJcP4+mU+iVGsOj7ZzOqZzT3vLKOJ1fsobzK4++wlFJdiE9HHxWRS4FHARfwrDHmDyLyELDGGLNYRP4KXARUA0eBe4wxW1paZ1fsNdQaFdUefvjaet7ffJgAgb6JEYxIiea2KWkMT+lkN01RSrU7HYa6i/DUGpbvyGZDeiFbM4tYvT+foopq5k/oxU+/M4i4cB2JUynVNH91H1VtzBUgTBvSjWlDugFQWF7NXz/exfNf7+ffGzO5eGh3JvSJZXyfOPolhmu3U6VUq2iJoAvYeaSYv368i6/35pFfaq9OHtw9kuvP6sUVY1J8f6tMpVSHp1VDDmGMYW9uKV/tzuW1NYfYnFFEmNvF3LEp3HxOGv2TIvwdolLKTzQROJAxhg3phbz49QHe3ZBJlaeW8wcmMn9CT84flEiYW2sFlXISTQQOl1tSySurDvLiygPkFFcSEhTA+QMTmTMmhYuHdscVoG0JSnV1mggUADWeWr7Zn8/SzYf5YMthjhRV0js+jNunpDF3bCrhwVpKUKqr0kSgTuCpNXy45TBPrNjL+kMFBIi9i9qIlBgmpsVyydDuxGp3VKW6DE0EqlnGGL49eJTPduayOaOQjekF5JZUERggTO6fwOUje3DJ0O5Eh2nPI6U6M00EqtWMMWzJLOLdjZm8tyGLjILyY0nhshE9uGRYN2LCtKSgVGejiUCdFmMMG9MLWbI5iyWbsjiUb5PClAEJzB6dzMyRyQS6/D6ArVKqFTQRqDNmjGFzRhHvbcrk3xuzSD9aTv+kCP7fdwZx8dBuehWzUh2cJgLVpowxLN1yhP9eup29OaUMSIrAFSDklVZRVVPLhYOTmDs2hXP6JWjXVKU6CE0EyidqPLW8tuYQ723IIiIkkPhwN9Uew0dbD1NUUUP3qBCuHJfCNeN70js+3N/hKuVomghUu6qo9vDp9mwWrU1n+Y5sag1MTItjYLcI4sLcxIa7SY0NIy0hjJ5xYQQHuvwdslJdno4+qtpVSJCLS0f04NIRPThcWMEb36bz7gbbtlBQXk39c48AgfG947hsZA9mDO+u92ZWyg+0RKDalafWUFBWxaGj5ezPLWVXdjEfb81mx5FiRGBMzximDkpi6qBEhidHE6BtDEq1Ca0aUh3eriPFvLcxi2U7stmYXghAfLibcwckcN7ARMb1jiUlJlS7qyp1mjQRqE4lt6SSFTtzWLEzh8935ZLnvcdCYIDQMy6MfokRDE2OYmiPKMb0iqGbVicpdVLaRqA6lYSIYOaOTWXu2FRqaw1bs4rYmlXE/txS9ueVsvNICZ9uP0Kt9xxmZGo0Fw/pxowR3emfFOnf4JXqhLREoDql8ioP2w4X8fWePD7aeoT1hwoAmNAnluvP6s2MEd21N5JS9WjVkOrysosqeHt9Bi+vOsiBvDICA4SIkEDC3YFEhQbRNzGcgUmRDOgWQWpsKMkxocSHu/WKaOUYmgiUY9TWGr7ck8tXe/IorayhrMpDfmkVu7KLOZRf3mDeiOBArhnfkzvOS6NHdKifIlaqfWgiUAooq6phb04pGQXlZBaUs+FQAe9uzCJAYOaoZOLC3JRU1lBa5SEyJJCEiGASI4MZlhzFiJRogrTHkurEtLFYKSDMHcjwlGiGp0Qfm/bjSwbx1Od7eX1NOiK2lBAeHEhReTX5ZVXHLn4Lc7sY1zuWqYOS+M6wbqTGhvlpK5Rqe1oiUAo7kF7j9oIaTy3ZxZWsO1jAqn15fL0nj13ZJQAMT4libC97bUNKbCipsWH0jgsjJixI2x1Uh6QlAqVOoqmDd6ArgOQY27B82cgeAOzPLWXplsN8tPUIb63LoLiipsEykcGBpMSG0iM6hO7RoaQlhDGmVyzDk6MJdWsvJtUxaYlAqTNQVFFNZkE5h/LLOZhfxsG8UjIKKsgqLCersIJ878VwrgBheHIU5w9M5PxBiYxKjdGrpFW70sZipfwkt6SS9QcL+PbgUVbty2fdwaPUGnC7AkiMtI3R3aNC6B0fRp+EcFJjQ4kMCSIi2EVEcBDxEW5tpFZtQquGlPKThIhgLhrajYuGdgOgsKyaL3bnsjGjgJyiSnJKKtmVXcyn27Op8tQ2uY64cDdJkcEMS45mdK8YRqVGEx0aRKArgCCXkBAerIPzqTOiJQKlOgBPrSGrsJz0o+WUeruwFldUk1NcSU5xJRkF5WxKLzw27lJ9IUEB9EuMYEBSBGkJEfRJCCMtIZyB3SIJCdJ2CWVpiUCpDs4VIKTGhrXYLdUYQ/rRcrZkFlJW5aHGY6is8XAgr4xd2SWs3n+Ut9dnHps/ODCACX3imNw/gciQQNtuUVBBUlQIc8emMLCbjsukLJ+WCERkOvBXwAU8bYx5uNHrPwJuB2qAHOBWY8yBltapJQKlmldR7eFgfhl7c2xi+HJ3LtsPFwM22XSLDCa7uJKaWsPwlCguHtKd/kkR9EsKJyEimIpqDxXVtYS6XSRHh2hX2C7EL43FIuICdgIXA+nAauBaY8zWevNcAKwyxpSJyF3AVGPMvJbWq4lAqVOTW1JJtaeWpMgQXAFCbkkli9dn8ua6dDZnFDW7XPeoECamxTEyNZq4cDcxYUEkRoQwpEek9njqhPxVNTQR2G2M2esNYgEwGziWCIwxy+rNvxK4wYfxKOVICRHBJzy/dUoat05Jo6yqhn25pezJKaWgrIqQQBfBQQEUlFWzen8+q/blsXhDZoPlo0ICmdw/gbP7xRMb5iY0yEV4cCDdooJJjgnVdolOyJeJIAU4VO95OnBWC/PfBrzf1AsicidwJ0CvXr3aKj6lHC/MHciw5GiGJUef8NpN5/TBGENBWTUF5dUUlldzKL+Mz3flsGJnLu9vPtzkOmPCgogJDSIqNIjIkEBiwtzEhbmJDXeTEhNCr7hweseHERfuJjgwQKufOoAO0VgsIjcA44Hzm3rdGPMk8CTYqqF2DE0pRxMRYsPtQRxgdM8YZo5KxhjD4aIKSirsCK8llTUcLrQX0h0uqqCwvIbiimqKyqvJKiziaGkVBeXVNK6JdgUIYW4XqbFhjEqNZlTPGGJCgyiqsIknLjyY8wcmkhgZ3ER0qq34MhFkAD3rPU/1TmtARC4Cfgmcb4yp9GE8Sqk2IiJ26O4TCxLNqvHUklVYwYG8Mg7kl1JYXk1ZpU0ie3JKWLIpiwWrD52wnAiMTI3h7L7xpCWE0SsunB7RIYQEuQgODCA8OBB3oLZZnAlfJoLVwAARScMmgPnAdfVnEJExwBPAdGNMtg9jUUr5WaArgJ5xYfSMC2MKCSe8bozhQF4Z5dUeokKDiAoJ5GB+GZ9uy+aT7dk888Veqj0nVgi4AoQBSREMS46mb2I4nlpDVU0tgS7hrLR4xvWO1URxEr7uPnop8Ci2++izxpg/iMhDwBpjzGIR+RgYAWR5FzlojJnV0jq115BSzlS/RHGkqIIqTy2V1R5ySirZmlnEpowicktspUJds4MxEO52MSEtjsiQIAIDBBGo9hgqqj14ag0DkiIY3yeOcb1jifNWgXVFOtaQUsoRKqo9BAYIga4ASipr+HpPHst3ZLP2wFGqamrxGEONxxAcGECwt3fT7uziYyWNpMhg+iSE09d7ZfbwlGiGJkcREhhAobfB3BUgxIS6iQwJ7FRDe2giUEqpZlRUe9iUUcjaA0fZk13CvtxS9uaWHhs5tjkBAgO7RTJzVDKzRiXTMy4MYwyVNbWUV3kw2OquEG/3Wn/TRKCUUqcou6iCzZmFbM0swlML0aGBRIcFUVsLBeXVHC2t4uu9eaw9cBSwgwOWVNQ0OXhg96gQ+iWF0zM2jFC3i5AgFy4RCsqryC+toqqmlvMHJXHZiB4+q57SRKCUUj5yKL+Mdzdmcii/nOjQIKJCAwkNciHY3lV1vaL25JSScbScymoPFTUeamoNsWFu4sLd1Hhq2Z9XRmCAcFbfOMLcgVTV1FJrDGN6xTJtcBIjUqLPqCpKE4FSSnUw9W+PaoxhW1Yxizdk8tnOHIwxuAMDqPEYth8uotbYK8J/ffkQZo9OOa3309FHlVKqg6l/RbWIMDQ5iqHJUTwwY3CD+fJLq/hsZzafbs+he1SIT2LRRKCUUh1YXLibOWNSmTMm1WfvoVdZKKWUw2kiUEoph9NEoJRSDqeJQCmlHE4TgVJKOZwmAqWUcjhNBEop5XCaCJRSyuE63RATIpIDHDjNxROA3DYMp7Nw4nY7cZvBmdvtxG2GU9/u3saYxKZe6HSJ4EyIyJrmxtroypy43U7cZnDmdjtxm6Ftt1urhpRSyuE0ESillMM5LRE86e8A/MSJ2+3EbQZnbrcTtxnacLsd1UaglFLqRE4rESillGpEE4FSSjmcYxKBiEwXkR0isltEHvB3PL4gIj1FZJmIbBWRLSJyn3d6nIh8JCK7vH9j/R1rWxMRl4isE5H3vM/TRGSVd3+/JiK+uSO4H4lIjIgsEpHtIrJNRM52yL7+off7vVlEXhWRkK62v0XkWRHJFpHN9aY1uW/F+pt32zeKyNhTfT9HJAIRcQGPATOAocC1IjLUv1H5RA3wY2PMUGAScLd3Ox8APjHGDAA+8T7vau4DttV7/ifgL8aY/sBR4Da/ROVbfwU+MMYMBkZht79L72sRSQHuBcYbY4YDLmA+XW9//wuY3mhac/t2BjDA+7gT+OepvpkjEgEwEdhtjNlrjKkCFgCz/RxTmzPGZBljvvX+X4w9MKRgt/V572zPA1f4JUAfEZFU4DLgae9zAS4EFnln6YrbHA2cBzwDYIypMsYU0MX3tVcgECoigUAYkEUX29/GmBVAfqPJze3b2cALxloJxIhIj1N5P6ckghTgUL3n6d5pXZaI9AHGAKuAbsaYLO9Lh4Fu/orLRx4F/h9Q630eDxQYY2q8z7vi/k4DcoDnvFViT4tIOF18XxtjMoA/AwexCaAQWEvX39/Q/L494+ObUxKBo4hIBPAGcL8xpqj+a8b2F+4yfYZF5HIg2xiz1t+xtLNAYCzwT2PMGKCURtVAXW1fA3jrxWdjE2EyEM6JVShdXlvvW6ckggygZ73nqd5pXY6IBGGTwMvGmDe9k4/UFRW9f7P9FZ8PTAZmich+bJXfhdi68xhv1QF0zf2dDqQbY1Z5ny/CJoauvK8BLgL2GWNyjDHVwJvY70BX39/Q/L494+ObUxLBamCAt2eBG9u4tNjPMbU5b934M8A2Y8wj9V5aDNzk/f8m4J32js1XjDE/N8akGmP6YPfrp8aY64FlwFXe2brUNgMYYw4Dh0RkkHfSNGArXXhfex0EJolImPf7XrfdXXp/ezW3bxcD3/X2HpoEFNarQmodY4wjHsClwE5gD/BLf8fjo22cgi0ubgTWex+XYuvMPwF2AR8Dcf6O1UfbPxV4z/t/X+AbYDfwOhDs7/h8sL2jgTXe/f02EOuEfQ38DtgObAZeBIK72v4GXsW2gVRjS3+3NbdvAcH2itwDbML2qDql99MhJpRSyuGcUjWklFKqGZoIlFLK4TQRKKWUw2kiUEoph9NEoJRSDqeJQCkfE5GpdaOiKtURaSJQSimH00SglJeI3CAi34jIehF5wnuPgxIR+Yt3/PtPRCTRO+9oEVnpHf/9rXpjw/cXkY9FZIOIfCsi/byrj6h374CXvVfFIiIPe+8fsVFE/uynTVcOp4lAKUBEhgDzgMnGmNGAB7geO6jZGmPMMOAz4EHvIi8APzPGjMRezVk3/WXgMWPMKOAc7NWhYEeCvR97P4y+wGQRiQfmAMO86/m9L7dRqeZoIlDKmgaMA1aLyHrv877Yoa1f887zEjDFey+AGGPMZ97pzwPniUgkkGKMeQvAGFNhjCnzzvONMSbdGFOLHfqjD3YI5QrgGRGZC9TNq1S70kSglCXA88aY0d7HIGPMb5uY73THZKms978HCDR2/PyJ2JFDLwc+OM11K3VGNBEoZX0CXCUiSXDs/rC9sb+RulEtrwO+MMYUAkdF5Fzv9BuBz4y9K1y6iFzhXUewiIQ194be+0ZEG2OWAD/E3m5SqXYXePJZlOr6jDFbReRXwIciEoAd9fFu7A1fJnpfy8a2I4AdBvhx74F+L3CLd/qNwBMi8pB3HVe38LaRwDsiEoItkfyojTdLqVbR0UeVaoGIlBhjIvwdh1K+pFVDSinlcFoiUEoph9MSgVJKOZwmAqWUcjhNBEop5XCaCJRSyuE0ESillMP9f0di4ZPFy8vmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train('TPE','內湖區')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318e4321-5c4f-497d-957f-e404998911c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(f'./TPE/內湖區/111_result.csv')\n",
    "data['y - 0'] = data['y'] - data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6bda7a-84a5-497d-a425-d21e65172fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y10'] = data['y'] / 10\n",
    "data['y20'] = data['y'] / 5\n",
    "data['y30'] = data['y'] / 3.333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fb6fa8-80ef-45e2-930d-0e9caf907322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>交易年份</th>\n",
       "      <th>屋齡</th>\n",
       "      <th>交易標的</th>\n",
       "      <th>建物現況格局-房</th>\n",
       "      <th>建物現況格局-廳</th>\n",
       "      <th>建物現況格局-衛</th>\n",
       "      <th>電梯</th>\n",
       "      <th>floor</th>\n",
       "      <th>車位類別-坡道平面</th>\n",
       "      <th>...</th>\n",
       "      <th>STOP_COUNT_500</th>\n",
       "      <th>STOP_COUNT_750</th>\n",
       "      <th>NEAR_MRT_250</th>\n",
       "      <th>NEAR_MRT_500</th>\n",
       "      <th>NEAR_MRT_750</th>\n",
       "      <th>NEAR_TRA_500</th>\n",
       "      <th>NEAR_TRA_750</th>\n",
       "      <th>y</th>\n",
       "      <th>0</th>\n",
       "      <th>y - 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157252</td>\n",
       "      <td>148493.22</td>\n",
       "      <td>8758.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232642</td>\n",
       "      <td>246799.72</td>\n",
       "      <td>-14157.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152755</td>\n",
       "      <td>152401.78</td>\n",
       "      <td>353.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227800</td>\n",
       "      <td>197753.81</td>\n",
       "      <td>30046.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138959</td>\n",
       "      <td>121627.46</td>\n",
       "      <td>17331.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>111</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228405</td>\n",
       "      <td>222055.44</td>\n",
       "      <td>6349.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>111</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149428</td>\n",
       "      <td>165253.61</td>\n",
       "      <td>-15825.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>111</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183706</td>\n",
       "      <td>162439.10</td>\n",
       "      <td>21266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>111</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271328</td>\n",
       "      <td>257214.55</td>\n",
       "      <td>14113.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>454</td>\n",
       "      <td>111</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180561</td>\n",
       "      <td>170297.84</td>\n",
       "      <td>10263.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  交易年份    屋齡  交易標的  建物現況格局-房  建物現況格局-廳  建物現況格局-衛  電梯  floor  \\\n",
       "0             0   111  38.0     0         3         2         2   0      3   \n",
       "1             1   111  17.0     1         3         2         2   1     11   \n",
       "2             2   111  35.0     0         2         1         2   0      4   \n",
       "3             3   111  25.0     0         2         2         1   1      6   \n",
       "4             4   111  35.0     0         3         2         2   0      3   \n",
       "..          ...   ...   ...   ...       ...       ...       ...  ..    ...   \n",
       "450         450   111  11.0     1         4         2         3   1      5   \n",
       "451         451   111  38.0     0         3         2         2   0      4   \n",
       "452         452   111  45.0     0         5         0         5   0      3   \n",
       "453         453   111  10.0     1         5         2         3   1      8   \n",
       "454         454   111  41.0     0         6         0         6   0      5   \n",
       "\n",
       "     車位類別-坡道平面  ...  STOP_COUNT_500  STOP_COUNT_750  NEAR_MRT_250  \\\n",
       "0          0.0  ...            10.0            28.0             0   \n",
       "1          1.0  ...            29.0            51.0             1   \n",
       "2          0.0  ...            11.0            34.0             0   \n",
       "3          0.0  ...            15.0            25.0             1   \n",
       "4          0.0  ...            18.0            28.0             0   \n",
       "..         ...  ...             ...             ...           ...   \n",
       "450        1.0  ...            21.0            39.0             1   \n",
       "451        0.0  ...            20.0            49.0             1   \n",
       "452        0.0  ...            20.0            36.0             1   \n",
       "453        1.0  ...            17.0            38.0             0   \n",
       "454        0.0  ...            24.0            52.0             1   \n",
       "\n",
       "     NEAR_MRT_500  NEAR_MRT_750  NEAR_TRA_500  NEAR_TRA_750       y  \\\n",
       "0               0             1             0             0  157252   \n",
       "1               1             1             0             0  232642   \n",
       "2               0             1             0             0  152755   \n",
       "3               1             1             0             0  227800   \n",
       "4               0             0             0             0  138959   \n",
       "..            ...           ...           ...           ...     ...   \n",
       "450             1             1             0             0  228405   \n",
       "451             1             1             0             0  149428   \n",
       "452             1             1             0             0  183706   \n",
       "453             0             1             0             0  271328   \n",
       "454             1             1             0             0  180561   \n",
       "\n",
       "             0     y - 0  \n",
       "0    148493.22   8758.78  \n",
       "1    246799.72 -14157.72  \n",
       "2    152401.78    353.22  \n",
       "3    197753.81  30046.19  \n",
       "4    121627.46  17331.54  \n",
       "..         ...       ...  \n",
       "450  222055.44   6349.56  \n",
       "451  165253.61 -15825.61  \n",
       "452  162439.10  21266.90  \n",
       "453  257214.55  14113.45  \n",
       "454  170297.84  10263.16  \n",
       "\n",
       "[455 rows x 86 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6139bb-74d3-44f8-acab-e0d1927fccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
